-patchCore를 사용했으나 무의미했고, Pytorch를 이용해서 AutoEncoder를 다시 구현함
- transform기반으로 진행
- rf와 앙상블 사용, optuna 사용하는 것이 Gride search보다 낮은 것으로 예상

참조: https://github.com/Junoflows/LG_Aimers_phase2
컬럼 너무 많기 때문에 데이터 전처리 필요해 보임

1. 범주형 컬럼들을 처리하지 못하는 모델들이 존재하고 범주형 컬럼들을 수치화할 경우 모델의 성능이 향상되기도 하기 때문에
범주형 컬럼들이 있다면 수치화 해야함 → 1차적 전처리 후 범주형 컬럼 12개 → 더미변수화, 라벨인코딩 등을 하기 이전에 데이터 형태를 파악해야함
2. 다른 수치형 데이터들도 하나의 클래스에 너무 치우친 경우 이진화(0과1) 해줄 수 있음

이후에 수치화 된 데이터들의 상관관계 파악해 상관계수가 큰 경우 해당 컬럼들을 삭제해주어야 함 (히트맵이나 VIF 지표)
→ 하지만 타겟 변수와 밀접한 변수라면 삭제하면 안되기 때문에 시각화해서 살펴보기

- f1 score를 제출하지 않고도 사용할 수 있게하는 방법이 있다.    
f1 올리려면… 재현성을 높여야 할 것 같다.
데이터 시각화 결과 6개의 feature이 normal과 abnormal의 차이가 잘 드러나는 것 처럼 보였다.    
gpt: “**validation data는 원본 데이터의 비율을 가지게 train data는 1:1로 맞춘 다음 학습하는데
validation data는 원본 데이터 비율 유지하게 한다음 validation data로 f1 스코어 계산해”**
